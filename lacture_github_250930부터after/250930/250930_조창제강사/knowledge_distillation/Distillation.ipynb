{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2a214f5-5996-4491-9155-0601a18086ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,glob, cv2\n",
    "import pandas as pd\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # GPU 사용 안 함\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, losses, optimizers, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae6a42bf-ea59-4c64-b68b-42da8e4fde32",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Distiller(tf.keras.Model):\n",
    "    def __init__(\n",
    "        self, student, teacher, \n",
    "        student_loss_fun, \n",
    "        distillation_loss_fun = tf.keras.losses.KLDivergence(),\n",
    "        temperature = 5.0, alpha = 0.5):\n",
    "        super().__init__()\n",
    "        self.student = student\n",
    "        self.teacher = teacher\n",
    "        self.temperature = temperature\n",
    "        self.alpha = alpha\n",
    "        self.student_loss_fun = student_loss_fun\n",
    "        self.distillation_loss_fun = distillation_loss_fun\n",
    "\n",
    "    def compile(self, optimizer, metrics=None):\n",
    "        super().compile()\n",
    "        self.optimizer = optimizer\n",
    "        if metrics is not None:\n",
    "            self.student_metric = metrics\n",
    "\n",
    "    def train_step(self, data):\n",
    "        x, y = data\n",
    "        # teacher는 훈련 안함\n",
    "        teacher_predictions = self.teacher(x, training=False)\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            student_predictions = self.student(x, training=True)\n",
    "            # 일반 loss (hard label)\n",
    "            student_loss = self.student_loss_fun(y, student_predictions)\n",
    "            # distillation loss (soft label)\n",
    "            student_soft = tf.nn.softmax(student_predictions / self.temperature)\n",
    "            teacher_soft = tf.nn.softmax(teacher_predictions / self.temperature) \n",
    "            distill_loss = self.distillation_loss_fun(teacher_soft, student_soft)\n",
    "            # 최종 loss (alpha 가중치)\n",
    "            loss = self.alpha * student_loss + (1 - self.alpha) * distill_loss * (self.temperature ** 2)\n",
    "        \n",
    "        grads = tape.gradient(loss, self.student.trainable_variables)\n",
    "        # 오차 역전파\n",
    "        self.optimizer.apply_gradients(zip(grads, self.student.trainable_variables))\n",
    "        \n",
    "        self.student_metric.update_state(y, tf.nn.softmax(student_predictions))\n",
    "        return {\"loss\": loss, \"accuracy\": self.student_metric.result()}\n",
    "    \n",
    "    def test_step(self, data):\n",
    "        x, y = data\n",
    "        student_predictions = self.student(x, training=False)\n",
    "        student_loss = self.student_loss_fun(y, student_predictions)\n",
    "        self.student_metric.update_state(y, tf.nn.softmax(student_predictions))\n",
    "        return {\"loss\": student_loss, \"accuracy\": self.student_metric.result()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a46e025-ab8b-4810-8e7a-9afd27b39f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ratio_padding(frame, H, W, value=255):\n",
    "    \"\"\"\n",
    "    비율을 유지하며 이미지를 HxW 크기로 padding 하는 함수\n",
    "    배경색은 value (기본 흰색: 255)\n",
    "\n",
    "    Args:\n",
    "        frame (np.array): 원본 이미지 (H_f, W_f, C) 또는 (H_f, W_f)\n",
    "        H (int): 출력 높이\n",
    "        W (int): 출력 너비\n",
    "        value (int, optional): 패딩 색상. 기본 255 (흰색)\n",
    "\n",
    "    Returns:\n",
    "        np.array: 크기 (H, W, C) 또는 (H, W)인 출력 이미지\n",
    "    \"\"\"\n",
    "    # 출력 배열 초기화 (채널 유지)\n",
    "    if len(frame.shape) == 2:  # 흑백 이미지\n",
    "        out = np.full((H, W), value, dtype=frame.dtype)\n",
    "    else:  # 컬러 이미지\n",
    "        out = np.full((H, W, frame.shape[-1]), value, dtype=frame.dtype)\n",
    "\n",
    "    f_H, f_W = frame.shape[:2]\n",
    "    aspect_ratio = f_H / f_W\n",
    "\n",
    "    if aspect_ratio < 1:  # 가로가 더 긴 이미지\n",
    "        if aspect_ratio * W > H:\n",
    "            # 높이를 기준으로 너비 조정\n",
    "            new_W = int(H / aspect_ratio)\n",
    "            resized = cv2.resize(frame, (new_W, H))\n",
    "            start_x = (W - new_W) // 2\n",
    "            out[:, start_x:start_x + new_W] = resized\n",
    "        else:\n",
    "            # 너비를 기준으로 높이 조정\n",
    "            new_H = int(aspect_ratio * W)\n",
    "            resized = cv2.resize(frame, (W, new_H))\n",
    "            start_y = (H - new_H) // 2\n",
    "            out[start_y:start_y + new_H, :] = resized\n",
    "    else:  # 세로가 더 긴 이미지 or 정사각형에 가까운 경우\n",
    "        new_W = int(H / aspect_ratio)\n",
    "        resized = cv2.resize(frame, (new_W, H))\n",
    "        start_x = (W - new_W) // 2\n",
    "        out[:, start_x:start_x + new_W] = resized\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cea6b93f-49c2-4fb0-9b66-1a98e1fc890f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, df, batch_size, preprocessing, aug_fun=None, is_test=False):\n",
    "        self.data = df\n",
    "        self.batch_size = batch_size \n",
    "        self.preprocessing = preprocessing\n",
    "        self.aug_fun = aug_fun\n",
    "        self.is_test = is_test\n",
    "    def __len__(self):\n",
    "        return np.ceil(self.data.shape[0] / self.batch_size).astype(int)\n",
    "    def __getitem__(self, index):\n",
    "        st = index * self.batch_size\n",
    "        ed = (index + 1) * self.batch_size\n",
    "        paths = self.data.values[st:ed]\n",
    "        x_list = []\n",
    "        y_list = []\n",
    "        for file_path in paths:\n",
    "            if self.is_test:\n",
    "                x = self.preprocessing(file_path, self.is_test)\n",
    "            else:\n",
    "                x, y = self.preprocessing(file_path)\n",
    "            if self.aug_fun:\n",
    "                x = self.aug_fun(image= x)[\"image\"]\n",
    "                x = np.clip(x, 0, 255)\n",
    "            x_list.append(x)\n",
    "            if not self.is_test:\n",
    "                y_list.append(y)\n",
    "        bat_x = np.array(x_list)\n",
    "        if self.is_test:\n",
    "            return bat_x\n",
    "        bat_y = np.array(y_list)\n",
    "        return bat_x, bat_y\n",
    "    def on_epoch_end(self):\n",
    "        self.data = self.data.sample(frac = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff0c4431-a9da-4d86-8aac-7bea537775b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.94259941, 0.04692926, 0.01047133]),\n",
       " array([0.51140921, 0.28066732, 0.20792347]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.special import softmax\n",
    "import numpy as np\n",
    "logits = np.array([5.0, 2.0, 0.5])\n",
    "softmax(logits) , softmax(logits / 5.0)  \n",
    "#Temperature로 나눴을 때 분포가 퍼짐\n",
    "# 티쳐가 더 많은 정보를 알려 줄 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88d2a05f-620d-4703-ba08-f085081231f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(\"data/**/*\")\n",
    "df = pd.DataFrame({\"path\":files})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae6b8417-ef43-4354-b0e4-1f966d2b8257",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(\n",
    "    df, test_size=0.2, random_state=42)\n",
    "valid_df, test_df = train_test_split(\n",
    "    test_df, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56b55c5d-7efe-4ba3-9d68-055be6e400a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(path):\n",
    "    img = cv2.imread(path)\n",
    "    img = ratio_padding(img, 224,224)\n",
    "    y = int(path.split(\"/\")[-1]==\"Cat\")\n",
    "    return img, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a8a6223-f641-43fa-9cf2-29caa066bf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_gen = MyGenerator(train_df[\"path\"], batch_size = 32, preprocessing=preprocessing)\n",
    "val_gen = MyGenerator(valid_df[\"path\"], batch_size = 32, preprocessing=preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7aa9515-7e72-48fd-8224-5fe3766d91b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(tr_gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b8942f8-d2be-4382-8db0-6b20f8eec4df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32, 224, 224, 3), (32,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "841904b6-33fa-468c-a0c1-52315bb92de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',    # 검증 손실 기준\n",
    "    factor=0.5,            # 학습률 줄이는 비율 (50%)\n",
    "    patience=6,            # 개선 없을 시 3 에폭 기다림\n",
    "    verbose=1,\n",
    "    min_lr=1e-7\n",
    ")\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,            # 7 에폭 동안 개선 없으면 중단\n",
    "    verbose=1,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "callbacks = [reduce_lr, early_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04da60e6-abfd-4a79-a1ec-ba5c0ed50b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-29 14:35:13.666594: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-09-29 14:35:13.677616: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-09-29 14:35:13.681543: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-09-29 14:35:13.684288: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-29 14:35:13.685374: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-09-29 14:35:13.689116: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-09-29 14:35:13.691936: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-09-29 14:35:14.496062: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-09-29 14:35:14.497584: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-09-29 14:35:14.498771: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-09-29 14:35:14.500124: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10068 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:22:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "inp = tf.keras.layers.Input((224,224,3))\n",
    "x = tf.keras.applications.efficientnet.preprocess_input(inp)\n",
    "backbone = tf.keras.applications.EfficientNetB0(\n",
    "    input_shape = (224, 224, 3), include_top=False)\n",
    "x = backbone(x)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "out = tf.keras.layers.Dense(1,activation=\"sigmoid\")(x)\n",
    "teacher = tf.keras.Model(inp, out)\n",
    "\n",
    "teacher.compile(\n",
    "    optimizer=optimizers.Adam(),\n",
    "    loss=losses.BinaryCrossentropy(),\n",
    "    metrics=[metrics.BinaryAccuracy()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aecf5807-0efd-4ad6-8d69-cbd2b06b6b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = f'model/teacher.h5'\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d80cd1-a534-4f60-95d0-473e5e3aef68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-29 14:35:29.602195: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8201\n",
      "2025-09-29 14:35:33.170734: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 39/586 [>.............................] - ETA: 2:47 - loss: 0.0449 - binary_accuracy: 0.9808   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 2230 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/586 [====>.........................] - ETA: 2:26 - loss: 0.0164 - binary_accuracy: 0.9931"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 226 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/586 [==========>...................] - ETA: 1:50 - loss: 0.0079 - binary_accuracy: 0.9967"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 254 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230/586 [==========>...................] - ETA: 1:48 - loss: 0.0077 - binary_accuracy: 0.9967"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 1403 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/586 [==================>...........] - ETA: 1:04 - loss: 0.0047 - binary_accuracy: 0.9980"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 239 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404/586 [===================>..........] - ETA: 56s - loss: 0.0044 - binary_accuracy: 0.9981 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 65 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "409/586 [===================>..........] - ETA: 54s - loss: 0.0043 - binary_accuracy: 0.9982"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: unknown JFIF revision number 0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429/586 [====================>.........] - ETA: 48s - loss: 0.0041 - binary_accuracy: 0.9983"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 399 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440/586 [=====================>........] - ETA: 44s - loss: 0.0040 - binary_accuracy: 0.9983"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 162 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "477/586 [=======================>......] - ETA: 33s - loss: 0.0037 - binary_accuracy: 0.9984"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 214 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "510/586 [=========================>....] - ETA: 23s - loss: 0.0035 - binary_accuracy: 0.9985"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 99 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "586/586 [==============================] - ETA: 0s - loss: 0.0030 - binary_accuracy: 0.9987 \n",
      "Epoch 1: val_loss improved from inf to 0.00001, saving model to model/teacher.h5\n",
      "586/586 [==============================] - 218s 343ms/step - loss: 0.0030 - binary_accuracy: 0.9987 - val_loss: 1.2106e-05 - val_binary_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "114/586 [====>.........................] - ETA: 2:25 - loss: 1.2140e-05 - binary_accuracy: 1.0000 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 2230 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124/586 [=====>........................] - ETA: 2:22 - loss: 1.2255e-05 - binary_accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 226 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/586 [=======>......................] - ETA: 2:11 - loss: 1.1848e-05 - binary_accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 1403 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187/586 [========>.....................] - ETA: 2:03 - loss: 1.1575e-05 - binary_accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 99 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192/586 [========>.....................] - ETA: 2:01 - loss: 1.1566e-05 - binary_accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 162 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/586 [===========>..................] - ETA: 1:43 - loss: 1.1342e-05 - binary_accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 65 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "357/586 [=================>............] - ETA: 1:10 - loss: 1.0747e-05 - binary_accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: unknown JFIF revision number 0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399/586 [===================>..........] - ETA: 57s - loss: 1.0539e-05 - binary_accuracy: 1.0000 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 214 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/586 [=====================>........] - ETA: 45s - loss: 1.0785e-05 - binary_accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 399 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "508/586 [=========================>....] - ETA: 23s - loss: 1.0439e-05 - binary_accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 239 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "515/586 [=========================>....] - ETA: 21s - loss: 1.0392e-05 - binary_accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 254 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "586/586 [==============================] - ETA: 0s - loss: 9.9294e-06 - binary_accuracy: 1.0000 \n",
      "Epoch 2: val_loss improved from 0.00001 to 0.00001, saving model to model/teacher.h5\n",
      "586/586 [==============================] - 196s 332ms/step - loss: 9.9294e-06 - binary_accuracy: 1.0000 - val_loss: 5.0978e-06 - val_binary_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 3/100\n",
      " 72/586 [==>...........................] - ETA: 2:37 - loss: 5.8727e-06 - binary_accuracy: 1.0000 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 239 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/586 [=====>........................] - ETA: 2:22 - loss: 5.6823e-06 - binary_accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 226 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181/586 [========>.....................] - ETA: 2:03 - loss: 5.5957e-06 - binary_accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 162 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185/586 [========>.....................] - ETA: 2:02 - loss: 5.5757e-06 - binary_accuracy: 1.0000"
     ]
    }
   ],
   "source": [
    "history = teacher.fit(\n",
    "    tr_gen,\n",
    "    validation_data= val_gen,\n",
    "    epochs=100,\n",
    "    callbacks=[*callbacks, checkpoint],\n",
    "    use_multiprocessing=True,\n",
    "    workers=4\n",
    "    )\n",
    "model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5994c5b-0854-4e73-a6d4-2dc96cff49ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher.trainable = False\n",
    "teacher.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36c170b-f121-4f1c-90ba-cadbe48a1717",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.classification.basic import ClassificationBuilder\n",
    "from utils.classification import vgg, res, mobile, efficient\n",
    "\n",
    "builder = ClassificationBuilder(\n",
    "    num_classes = 1, input_shape = (224,224,3),\n",
    "    activation = \"sigmoid\")\n",
    "\n",
    "args = {\n",
    "    'input_shape': (224, 224, 3),\n",
    "    'filters': [32, 64, 128, 256, 512],\n",
    "    'iters': [1, 2, 2, 6, 2]\n",
    "}\n",
    "student = builder.build(args, mobile.get_model)\n",
    "student.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebc875c-0ff5-47e5-be7d-d1828a3a6d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "distiller = Distiller(\n",
    "    student=student, teacher=teacher, \n",
    "    student_loss_fun = losses.CategoricalCrossentropy(from_logits=True),\n",
    "    temperature=5.0, alpha=0.5)\n",
    "distiller.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=tf.keras.metrics.CategoricalAccuracy()\n",
    ")\n",
    "\n",
    "checkpoint_path = f'model/student.h5'\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False  \n",
    ")\n",
    "\n",
    "distiller.fit(\n",
    "    tr_gen,\n",
    "    validation_data= val_gen,\n",
    "    epochs=100,\n",
    "    callbacks=[*callbacks, checkpoint],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1197e8a-ab15-4084-9743-8961205db3bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
