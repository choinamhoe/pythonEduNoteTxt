{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0545421-cc28-4381-a5ff-5bdeb1e78b1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob, cv2, torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torchvision import transforms, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "935ea721-5dee-4f95-b8c9-b4c3fae82d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1125fbb-d907-4e3c-98e2-1c70986e2e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs = glob.glob(\"cat_and_dog/Dog/*\")\n",
    "cats = glob.glob(\"cat_and_dog/Cat/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cca9571-c738-41e3-b102-4678924c4ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([\n",
    "    pd.DataFrame({\"label\":1,\"path\":dogs}),\n",
    "    pd.DataFrame({\"label\":0,\"path\":cats})\n",
    "], ignore_index = True).sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77fc0eb8-0c62-4565-a05b-649d1a57401d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryImageDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, img_size=(224,224), transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.img_size = img_size\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.df.loc[idx, 'path']\n",
    "        label = self.df.loc[idx, 'label']\n",
    "\n",
    "        # img = cv2.imread(img_path)  # BGR format\n",
    "        # img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # RGB로 변환\n",
    "        # img = cv2.resize(img, self.img_size)       # (width, height)\n",
    "        # numpy -> tensor, C,H,W, 0~1\n",
    "        # img = torch.from_numpy(img).permute(2,0,1).float() / 255.0\n",
    "\n",
    "        # Normalize (ImageNet 기준)\n",
    "        # mean = torch.tensor([0.485,0.456,0.406]).view(3,1,1)\n",
    "        # std  = torch.tensor([0.229,0.224,0.225]).view(3,1,1)\n",
    "        # img = (img - mean)/std\n",
    "\n",
    "        \n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, torch.tensor(label, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c4922ce-b912-4abf-8c42-4f3832b48a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],   # ImageNet mean\n",
    "                         std=[0.229, 0.224, 0.225])    # ImageNet std\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffde20ce-9342-4769-8ee4-5393ce0a1f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['label'], random_state=42)\n",
    "\n",
    "train_dataset = BinaryImageDataset(train_df, transform=transform)\n",
    "val_dataset = BinaryImageDataset(val_df, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a70f8a5b-155a-4369-b3df-1f6184f6fd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "class SimpleMobileNet(pl.LightningModule):\n",
    "    def __init__(self, lr=2e-5, scheduler_patience = 3):\n",
    "        super().__init__()\n",
    "        self.lr = lr\n",
    "        backbone  = models.mobilenet_v2(\n",
    "            weights=models.MobileNet_V2_Weights.IMAGENET1K_V1)\n",
    "        backbone.classifier = nn.Identity()\n",
    "        for p in backbone.features.parameters(): \n",
    "            p.requires_grad = False\n",
    "        self.backbone = backbone\n",
    "        \n",
    "        self.criterion = nn.BCEWithLogitsLoss()\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(1280, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()  \n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.head(x)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x,y = batch\n",
    "        y = y.unsqueeze(1)\n",
    "        loss = self.criterion(self(x), y)\n",
    "        return loss\n",
    "        \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y = y.unsqueeze(1)\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.log('val_loss', loss, prog_bar=True, on_epoch=True)\n",
    "        return loss\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d516ef3e-13fe-487a-83fd-284d007e0bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# 체크포인트 콜백: val_loss 기준으로 최적 모델 저장\n",
    "checkpoint_cb = ModelCheckpoint(\n",
    "    monitor='val_loss',      # 모니터링할 metric\n",
    "    mode='min',              # val_loss가 낮을수록 좋음\n",
    "    save_top_k=1,            # 가장 좋은 1개만 저장\n",
    "    filename='best_model'    # 저장될 파일 이름\n",
    ")\n",
    "\n",
    "# 얼리스탑 콜백: val_loss 개선 없으면 조기 종료\n",
    "earlystop_cb = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,              # 5 epoch 동안 개선 없으면 종료\n",
    "    mode='min'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51050121-efae-4871-a1dc-120d52dab873",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3060') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type              | Params\n",
      "------------------------------------------------\n",
      "0 | backbone  | MobileNetV2       | 2.2 M \n",
      "1 | criterion | BCEWithLogitsLoss | 0     \n",
      "2 | head      | Sequential        | 328 K \n",
      "------------------------------------------------\n",
      "328 K     Trainable params\n",
      "2.2 M     Non-trainable params\n",
      "2.6 M     Total params\n",
      "10.208    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f894d5a326643e9a36195d9dea64ed0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b20d15c7061b40ce9eded4530d7b7e26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "model = SimpleMobileNet()\n",
    "loss_callback = LossHistoryCallback()\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=10,\n",
    "    accelerator='auto', # GPU 자동 감지\n",
    "    devices=1,# GPU 하나 사용 (없으면 CPU)\n",
    "    callbacks=[checkpoint_cb, earlystop_cb],\n",
    ")\n",
    "trainer.fit(model, train_loader, val_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39ed17f-11a7-4e07-945d-4aa7a559950c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# batch 단위 loss → epoch 평균\n",
    "train_losses = np.array(loss_callback.train_losses).reshape(trainer.max_epochs, -1).mean(axis=1)\n",
    "val_losses = np.array(loss_callback.val_losses).reshape(trainer.max_epochs, -1).mean(axis=1)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(range(1, trainer.max_epochs+1), train_losses, label='Train Loss')\n",
    "plt.plot(range(1, trainer.max_epochs+1), val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Train / Validation Loss Curve')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ab56fc-3226-4cf3-bc42-200cb713168b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4982c743-a459-4e7c-a058-ff62e0ac1a70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a918a2ee-c16a-4cf8-b41a-0c382202c6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------\n",
    "class SimpleBinaryModel(nn.Module):\n",
    "    def __init__(self, input_dim=10):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)  # BCEWithLogitsLoss 사용 → Sigmoid 제거\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "model = SimpleBinaryModel()\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = model.to(device)\n",
    "\n",
    "# ------------------------\n",
    "# 3. 손실 함수 & 옵티마이저\n",
    "# ------------------------\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# ------------------------\n",
    "# 4. 학습 루프\n",
    "# ------------------------\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # --- train ---\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for x, y in train_loader:\n",
    "        x, y = x.to(device), y.to(device).unsqueeze(1)  # [B] -> [B,1]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        y_hat = model(x)\n",
    "        loss = criterion(y_hat, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * x.size(0)\n",
    "\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "\n",
    "    # --- validation ---\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            x, y = x.to(device), y.to(device).unsqueeze(1)\n",
    "            y_hat = model(x)\n",
    "            loss = criterion(y_hat, y)\n",
    "            val_loss += loss.item() * x.size(0)\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
