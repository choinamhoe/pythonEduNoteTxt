{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa23cbfb-f7af-4900-b3cc-52d939e144b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-01 15:41:42.798399: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-09-01 15:41:42.808970: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-09-01 15:41:42.812850: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob, cv2\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa21f83e-d9e4-4c6d-997a-6a4c7db78014",
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs = glob.glob(\"cat_and_dog/Dog/*\")\n",
    "cats = glob.glob(\"cat_and_dog/Cat/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "523746d2-97e9-4de7-a709-b7bb9bd08f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([\n",
    "    pd.DataFrame({\"label\":1,\"path\":dogs}),\n",
    "    pd.DataFrame({\"label\":0,\"path\":cats})\n",
    "], ignore_index = True).sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c4b09ca-295b-4fa6-a5d6-1d2b3aadf4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path, img_size):\n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, img_size)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82b72ae3-691f-4ca2-ab0b-c3ca60017d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, df, function, batch_size = 32,\n",
    "                 image_size = (224, 224), shuffle = True):\n",
    "        \n",
    "        self.df = df\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = image_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indices = np.arange(len(self.df))\n",
    "        self.on_epoch_end()\n",
    "        self.function = function\n",
    "    # 배치를 몇번 반복할지 반환\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(self.df.shape[0] / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_indices = self.indices[\n",
    "            index*self.batch_size : (index+1)*self.batch_size]\n",
    "        batch_df = self.df.iloc[batch_indices]\n",
    "        \n",
    "        batch_images = np.array([self.function(\n",
    "            p, self.img_size) for p in batch_df['path']])\n",
    "        batch_labels = np.array(batch_df['label'])\n",
    "        \n",
    "        return batch_images, batch_labels\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef396b70-42b2-4826-a89e-dff532e3ddd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(\n",
    "    df, test_size=0.2, random_state=42, stratify=df['label'])\n",
    "test_df, val_df = train_test_split(\n",
    "    val_df, test_size=0.5, random_state=42, stratify=val_df['label'])\n",
    "train_gen = MyGenerator(train_df,load_image, batch_size=32)\n",
    "val_gen = MyGenerator(val_df, load_image, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4af2e074-9860-42ca-8e98-934fb2fab8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-01 15:41:42.971589: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-01 15:41:42.972719: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-09-01 15:41:42.976614: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-09-01 15:41:42.979370: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-09-01 15:41:43.765651: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-09-01 15:41:43.767436: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-09-01 15:41:43.768756: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-09-01 15:41:43.769961: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10077 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:22:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "backbone = tf.keras.applications.MobileNetV2(\n",
    "    input_shape = (224,224,3), include_top = False)\n",
    "backbone.trainable = False\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape=(224,224,3))\n",
    "x = tf.keras.applications.mobilenet_v2.preprocess_input(inputs)\n",
    "x = backbone(x)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4ef7bc9-7060-47b7-81a8-4cea605a905a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf87f505-32b3-491e-a66d-9b9c86f2dca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 45/586 [=>............................] - ETA: 1:24 - loss: 0.0098 - binary_accuracy: 0.9972    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Keras_worker_ForkPoolWorker-80:\n",
      "Process Keras_worker_ForkPoolWorker-76:\n",
      "Process Keras_worker_ForkPoolWorker-74:\n",
      "Process Keras_worker_ForkPoolWorker-75:\n",
      "Process Keras_worker_ForkPoolWorker-77:\n",
      "Process Keras_worker_ForkPoolWorker-78:\n",
      "Process Keras_worker_ForkPoolWorker-79:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/conda/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/conda/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/conda/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/conda/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/conda/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/conda/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/conda/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/conda/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/conda/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/conda/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/conda/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/conda/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/conda/lib/python3.9/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/conda/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/conda/lib/python3.9/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/conda/lib/python3.9/multiprocessing/queues.py\", line 365, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/conda/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/conda/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/conda/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/conda/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/conda/lib/python3.9/site-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/home/conda/lib/python3.9/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/conda/lib/python3.9/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/conda/lib/python3.9/site-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/home/conda/lib/python3.9/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/conda/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/conda/lib/python3.9/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/tmp/ipykernel_3512/2453420304.py\", line 21, in __getitem__\n",
      "    batch_images = np.array([self.function(\n",
      "  File \"/home/conda/lib/python3.9/multiprocessing/connection.py\", line 414, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/conda/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/tmp/ipykernel_3512/2453420304.py\", line 21, in __getitem__\n",
      "    batch_images = np.array([self.function(\n",
      "  File \"/home/conda/lib/python3.9/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/conda/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/conda/lib/python3.9/site-packages/keras/utils/data_utils.py\", line 566, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/tmp/ipykernel_3512/2453420304.py\", line 21, in <listcomp>\n",
      "    batch_images = np.array([self.function(\n",
      "  File \"/home/conda/lib/python3.9/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/tmp/ipykernel_3512/2453420304.py\", line 21, in <listcomp>\n",
      "    batch_images = np.array([self.function(\n",
      "  File \"/home/conda/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/tmp/ipykernel_3512/2503503005.py\", line 2, in load_image\n",
      "    img = cv2.imread(path)\n",
      "KeyboardInterrupt\n",
      "  File \"/tmp/ipykernel_3512/2453420304.py\", line 21, in __getitem__\n",
      "    batch_images = np.array([self.function(\n",
      "KeyboardInterrupt\n",
      "  File \"/tmp/ipykernel_3512/2503503005.py\", line 2, in load_image\n",
      "    img = cv2.imread(path)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/tmp/ipykernel_3512/2453420304.py\", line 21, in <listcomp>\n",
      "    batch_images = np.array([self.function(\n",
      "KeyboardInterrupt\n",
      "  File \"/tmp/ipykernel_3512/2503503005.py\", line 3, in load_image\n",
      "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
      "KeyboardInterrupt\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "loss = tf.keras.losses.BinaryCrossentropy()\n",
    "metrics = [tf.keras.metrics.BinaryAccuracy()]\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=loss,\n",
    "    metrics=metrics\n",
    ")\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=10,\n",
    "    workers=4,                 # CPU 코어 수에 맞춰 조정\n",
    "    use_multiprocessing=True,  # 병렬 처리 활성화\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da7c375-9321-41f7-b3fc-c9f8f4ad7e11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
