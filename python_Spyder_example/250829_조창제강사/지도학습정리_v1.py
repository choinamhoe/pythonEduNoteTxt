"""
지도학습: 뚜렷하게 정답이 있을 때 모델을 만드는 방식 중 하나
분류: 독립변수를 기반으로 카테고리를 분류하는 모델을 만드는 기법
    KNN: 예측하려는 지점을 기준으로 학습데이터 중 가까이 존재하는 
        K개에 대한 최빈값을 최종 예측값으로 제시하는 알고리즘
    DT: 모든 독립 변수들의 범위를 다 종속변수를 분류해보고, 
    그 중 가장 잘 분류(순수하게)되게 해주는 기준값과 변수를 찾는 행위를
    반복하여 나무형태로 만드는 알고리즘. 해석이 용이하다.
    목적함수: 지니지수, 엔트로피
        불순도: 변수 기준값을 고려해서 분리했을 때, 
            얼마나 깔끔하게 분리되는지를 나타내는 정도
            분리가 잘 안되면 불순도가 높음
        정보획득량: 변수 기준값을 고려해서 분리하기 전과 후의 불순도의 변화량
            개선된 정도를 정보획득량
        변수중요도:
            각 변수에 대한 정보획득량의 합산값을 그래프로 시각화한 것
    Logistic:
        일반화 선형 회귀모델(GLM): 
            선형회귀를 일반화해서 비선형성도 고려하는 형태로 변형
        로지스틱회귀:
            로짓이라는 것을 고려해서 예측값의 범위를 0~1사이의 값으로 
            나타나게 만든 일반화 선형회귀 모델 중 하나
    배깅:
        부트스트랩: 복원추출로 여러개의 모델을 생성
        집계(Aggregate): 여러개의 모델의 예측값을 집계하여 최빈값으로 제시
        부트스트랩을 활용하여 여러 개의 모델을 생성하고,
            그 생성된 모델의 예측값을 집계하여 최종 값으로 제시하는 알고리즘
        대표적인 모델로 랜덤포레스트가 있음. 
            랜덤포레스트는 여러 개의 모델을 만들때 의사결정트리를 사용한 방식
    부스팅 모델:
        전체 데이터를 기준으로 모델을 하나 만들고, 이 모델이 잘 못맞춘 데이터가
        더 자주 등장하도록 가중치를 주어서 복원 추출을 수행
        가중복원추출을 통해 나온값으로 모델을 생성
        이번에 생성된 모델이 잘 못맞추는 데이터를 산출하고, 가중치를 새로 부여
        부여된 가중치로 새로운 모델을 생성
        이를 반복해서 앞에서 못맞춘 데이터를 좀 더 잘 맞추게 학습
        마찬가지로 최빈값 제시하는 형태로 사용
"""
"""
회귀: 독립변수를 기반으로 수치값을 추론(추정)하는 기법
    KNN: 예측하려는 지점을 기준으로 학습데이터 중 가까이 존재하는 
        K개에 대한 평균값을 최종 예측값으로 제시하는 알고리즘
    회귀모형(Linear Regression): 독립변수를 바탕으로 종속변수를 
    가장 잘 설명하는 직선이나 평면을 찾는 알고리즘
    일반화 회귀 모델(Lasso, Ridge, ElasticNet): 
        회귀모델이 과적합하지않게 목적함수를 MSE값만이 아니라 
        Beta 값까지 규재하는 회귀모델을 일반화 회귀 모델.
        beta항에 대한 Lasso는 절대값, Ridge는 제곱값을 목적함수에 추가로 고려
        ElasticNet은 절대값 제곱값 둘 다 고려
    DT: 모든 독립 변수들의 범위를 다 종속변수를 분류해보고, 
    그 중 가장 잘 분류(순수하게)되게 해주는 기준값과 변수를 찾는 행위를
    반복하여 나무형태로 만드는 알고리즘. 
        목적함수: F통계량의 분산비
    배깅, 부스팅 모델: 회귀에서는 최빈값이 아니라 평균값을 사용
"""

"""
데이터 전처리: 데이터의 분포나 특성을 활용하여, 파생변수를 생성하거나, 
    예측성능향상을 위해서 데이터의 이상치나 결측치에 대해 처리하는 과정
    데이터 시각화, 기술통계량, 도메인 지식
    결측치 제거: 관측되지 않은 값을 어떻게 처리할 것인가를 고민하는 과정
        해당행 제거, 분석에 활용하는 컬럼을 기준으로 제거,
        평균으로 대체, 시간적 특성을 고려해서 대체
        결측치 보간:
            시간적 특성을 고려 - 칼만필터, 시계열 모델 활용
            공간적 특성을 고려(몰라도 될 것 같긴 합니다) - IDW, 크리깅 등
        그 외 다양한 방식으로 대체 가능
    변수변환:
        독립변수의 범위나 분포를 변형시키는 것을 의미
        표준화, min max 정규화(0~1, -1~1), 
        BoxCox -> 정규성과 독립성을 어느정도 만족하게 분포 변환
        이 밖에도 다양하게 존재
모델링:
    지도학습, 비지도학습 등
검증:
    검증방식: 모델이 얼마나 잘 맞는지를 데이터를 활용하여 객관적으로 평가하는 방식
        Hold Out Cross Validation:
            Train/Valid/Test 데이터를 3분할하여, 
                모델학습에는 Train만 활용
                하이퍼파라미터 최적화에는 Valid만 활용
                모델의 검증에는 Test만 활용하는 방식
        K fold Cross Validation(진행예정):
            데이터를 K 개로 분할해서 검증
        Stratified K fold Cross Validation(진행예정):
            데이터를 K 개로 분할할 때 층화추출을 활용
    성능평가지표: 모델이 우리가 원하는 성능으로 나오는지 평가하기 위한 
        객관적인 지표/함수
        분류: 
            정확도(Accuracy): 전체 테스트 데이터 중에서 모델이 맞춘 정도
            정밀도(Precision): 모델이 True라고 예측한 값 중 실제 True 값을 의미
            재현율(Recall): 실제 True 값 중에서 모델이 True라고 예측한 비율
            특이도(Specificity): 실제False 값 중 모델이 False 라고 예측한 값을 의미(수정)
            F1Score : 정밀도와 재현율의 조화 평균
        회귀:
            평균제곱오차(MSE): 오차의 제곱의 평균
            평균제곱근오차(RMSE): 평균제곱오차의 제곱근, MAE랑 범위가 거의 유사
            절대제곱오차(MAE): 오차의 절대값의 평균, 해석이 용이
                평균적으로 오차가 얼마가 난다.
"""
# 18분 시작
"""
K fold Cross Validation(진행예정):
    데이터를 K 개로 분할해서 검증
Stratified K fold Cross Validation(진행예정):
    데이터를 K 개로 분할할 때 층화추출을 활용

하이퍼 파라미터 최적화 - AI 모델 옵션 최적화
 - GridSearch: 기재한 모든 조합을 다 테스트 하는 방식
 - Randomize Search: 기재한 범위 내에서 n_inters만큼 랜덤하게 반복하는 방식
 - Bayesian Search: 기재한 범위 내에서 n_inters만큼 가우시안과정이라는 걸 활용해서 
     하이퍼파라메터를 최적화하는 방식

비지도학습: 명확한 레이블 없이 데이터(독립변수)의 유사성을 기반으로 묶는 방식
 - K means: 거리기반, 분석하기전에 k개를 설정해주어야 한다. 
        랜덤생성된초기 K값에 위치에 따라 군집이 결정되서 민감하다.
 - 계층적군집: 거리기반, 결과를 보고 군집을 분석하는 사람이 결정 가능하다.
 - DBSCAN: 밀도기반, k개를 결정할 수 없고, 
     허용오차(eps 입실론)에 따라 자동으로 결정된다.

차원축소: 변수선택과 달리 모든 변수를 활용하면서, 차원의 수(변수 개수)를 줄여주는 방식
 - PCA: 공분산(상관계수)을 활용하여, 고유값분해를 사용하여 축을 변형하고 
     차원을 축소하는 방식
     > 공분산이나 상관계수를 사용하므로 비선형적 특징을 고려할 수 없다.
 - tSNE: 비선형적 특징을 고려할 수 있으나, 차원축소로 인한 손실이 많이 발생하여 
     분석에는 변수로 잘 활용하지 않음.
     > 시각화 할 때 주로 활용
"""