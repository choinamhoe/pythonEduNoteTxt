"""
지도학습: 뚜렷하게 정답이 있을 때 모델을 만드는 방식 중 하나
분류: 독립변수를 기반으로 카테고리를 분류하는 모델을 만드는 기법
    KNN: 예측하려는 지점을 기준으로 학습데이터 중 가까이 존재하는 
        K개에 대한 최빈값을 최종 예측값으로 제시하는 알고리즘
    DT: 모든 독립 변수들의 범위를 다 종속변수를 분류해보고, 
    그 중 가장 잘 분류(순수하게)되게 해주는 기준값과 변수를 찾는 행위를
    반복하여 나무형태로 만드는 알고리즘. 해석이 용이하다.
    목적함수: 지니지수, 엔트로피
        불순도: 변수 기준값을 고려해서 분리했을 때, 
            얼마나 깔끔하게 분리되는지를 나타내는 정도
            분리가 잘 안되면 불순도가 높음
        정보획득량: 변수 기준값을 고려해서 분리하기 전과 후의 불순도의 변화량
            개선된 정도를 정보획득량
        변수중요도:
            각 변수에 대한 정보획득량의 합산값을 그래프로 시각화한 것
    Logistic:
        일반화 선형 회귀모델(GLM): 
            선형회귀를 일반화해서 비선형성도 고려하는 형태로 변형
        로지스틱회귀:
            로짓이라는 것을 고려해서 예측값의 범위를 0~1사이의 값으로 
            나타나게 만든 일반화 선형회귀 모델 중 하나
    배깅:
        부트스트랩: 복원추출로 여러개의 모델을 생성
        집계(Aggregate): 여러개의 모델의 예측값을 집계하여 최빈값으로 제시
        부트스트랩을 활용하여 여러 개의 모델을 생성하고,
            그 생성된 모델의 예측값을 집계하여 최종 값으로 제시하는 알고리즘
        대표적인 모델로 랜덤포레스트가 있음. 
            랜덤포레스트는 여러 개의 모델을 만들때 의사결정트리를 사용한 방식
    부스팅 모델:
        전체 데이터를 기준으로 모델을 하나 만들고, 이 모델이 잘 못맞춘 데이터가
        더 자주 등장하도록 가중치를 주어서 복원 추출을 수행
        가중복원추출을 통해 나온값으로 모델을 생성
        이번에 생성된 모델이 잘 못맞추는 데이터를 산출하고, 가중치를 새로 부여
        부여된 가중치로 새로운 모델을 생성
        이를 반복해서 앞에서 못맞춘 데이터를 좀 더 잘 맞추게 학습
        마찬가지로 최빈값 제시하는 형태로 사용
"""
"""
회귀: 독립변수를 기반으로 수치값을 추론(추정)하는 기법
    KNN: 예측하려는 지점을 기준으로 학습데이터 중 가까이 존재하는 
        K개에 대한 평균값을 최종 예측값으로 제시하는 알고리즘
    회귀모형(Linear Regression): 독립변수를 바탕으로 종속변수를 
    가장 잘 설명하는 직선이나 평면을 찾는 알고리즘
    일반화 회귀 모델(Lasso, Ridge, ElasticNet): 
        회귀모델이 과적합하지않게 목적함수를 MSE값만이 아니라 
        Beta 값까지 규재하는 회귀모델을 일반화 회귀 모델.
        beta항에 대한 Lasso는 절대값, Ridge는 제곱값을 목적함수에 추가로 고려
        ElasticNet은 절대값 제곱값 둘 다 고려
    DT: 모든 독립 변수들의 범위를 다 종속변수를 분류해보고, 
    그 중 가장 잘 분류(순수하게)되게 해주는 기준값과 변수를 찾는 행위를
    반복하여 나무형태로 만드는 알고리즘. 
        목적함수: F통계량의 분산비
    배깅, 부스팅 모델: 회귀에서는 최빈값이 아니라 평균값을 사용
"""

"""
데이터 전처리: 데이터의 분포나 특성을 활용하여, 파생변수를 생성하거나, 
    예측성능향상을 위해서 데이터의 이상치나 결측치에 대해 처리하는 과정
    데이터 시각화, 기술통계량, 도메인 지식
    결측치 제거: 관측되지 않은 값을 어떻게 처리할 것인가를 고민하는 과정
        해당행 제거, 분석에 활용하는 컬럼을 기준으로 제거,
        평균으로 대체, 시간적 특성을 고려해서 대체
        결측치 보간:
            시간적 특성을 고려 - 칼만필터, 시계열 모델 활용
            공간적 특성을 고려(몰라도 될 것 같긴 합니다) - IDW, 크리깅 등
        그 외 다양한 방식으로 대체 가능
    변수변환:
        독립변수의 범위나 분포를 변형시키는 것을 의미
        표준화, min max 정규화(0~1, -1~1), 
        BoxCox -> 정규성과 독립성을 어느정도 만족하게 분포 변환
        이 밖에도 다양하게 존재
모델링:
    지도학습, 비지도학습 등
검증:
    검증방식: 모델이 얼마나 잘 맞는지를 데이터를 활용하여 객관적으로 평가하는 방식
        Hold Out Cross Validation:
            Train/Valid/Test 데이터를 3분할하여, 
                모델학습에는 Train만 활용
                하이퍼파라미터 최적화에는 Valid만 활용
                모델의 검증에는 Test만 활용하는 방식
            K fold Cross Validation:
                데이터를 K개로 분활해서 검증
            Stratified K fold Cross Validation:
                데이터를 K개로 분할할 때 층화추출로 활용

    성능평가지표: 모델이 우리가 원하는 성능으로 나오는지 평가하기 위한 객관적인 지표/함수
        분류:
            정확도(Accuracy) : 전체 테스트데이터중에서 모델이 맞춘 정도
            정밀도(Precision) : 모델이 True라고 예측한 값 중 실제 True 값
            재현율(Recall) : 모델이 실제 True값 중에 True라고 예측한 비율
            특이도 : 모델이 실제  False값 중에 예측한 값중 실제 False 값을 의미
            F1Score : 정밀도와 재현율의 조화 평균 : 2 * (정밀도*재현율) / (정밀도+ 재현율)
        회귀:
            평균제곱오차(MSE): 오차의 제곱의 평균
            평균제곱근오차(RMSE): 평균제곱오차의 제곱근, MAE랑 범위가 거의 유사
            절대제곱오차(MAE): 오차의 절대값의 평균, 해석이 용이
                평균적으로 오차가 얼마가 난다.
"""
# 40분 시작
